{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naughty-element",
   "metadata": {},
   "source": [
    "# Digit Classification Task\n",
    "\n",
    "In this Experiment, we carry a digit classification task based on the MNIST dataset.\n",
    "We begin by importing the relevant modules and the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "angry-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Relevant Tensorflow functions\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stuffed-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Relevant \n",
    "from functools import partial\n",
    "import time\n",
    "import os, sys\n",
    "# Import hessianlearn repository\n",
    "sys.path.append( os.environ.get('HESSIANLEARN_PATH', \"../../\"))\n",
    "from hessianlearn import *\n",
    "from hessianlearn.hessianlearn.data.data import Data\n",
    "from hessianlearn.hessianlearn.problem.problem import ClassificationProblem,  AutoencoderProblem\n",
    "from hessianlearn.hessianlearn.problem.regularization import L2Regularization\n",
    "from hessianlearn.hessianlearn.model.model import HessianlearnModelSettings, HessianlearnModel\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-landscape",
   "metadata": {},
   "source": [
    "Import the MNIST dataset and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polished-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the mnist\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "#setting the train\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "#setting the test\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-youth",
   "metadata": {},
   "source": [
    "## Train Baseline Models\n",
    "\n",
    "We now train the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "phantom-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 469 steps, validate on 79 steps\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - ETA: 0s - batch: 234.0000 - size: 1.0000 - loss: 0.3071 - sparse_categorical_accuracy: 0.8983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 44s 86ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.3071 - sparse_categorical_accuracy: 0.8983 - val_loss: 0.0549 - val_sparse_categorical_accuracy: 0.9829\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 35s 67ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0548 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.0452 - val_sparse_categorical_accuracy: 0.9854\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 34s 67ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0392 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.0314 - val_sparse_categorical_accuracy: 0.9908\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 37s 73ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0289 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0271 - val_sparse_categorical_accuracy: 0.9920\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 36s 70ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0232 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.0276 - val_sparse_categorical_accuracy: 0.9902\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 38s 75ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0204 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0319 - val_sparse_categorical_accuracy: 0.9889\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 39s 75ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0165 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 0.9920\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 39s 77ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0151 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.0293 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 40s 78ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0118 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0302 - val_sparse_categorical_accuracy: 0.9911\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 39s 77ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0110 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0268 - val_sparse_categorical_accuracy: 0.9920\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 39s 76ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0092 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0266 - val_sparse_categorical_accuracy: 0.9928\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 41s 81ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0075 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0320 - val_sparse_categorical_accuracy: 0.9910\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 38s 74ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0088 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0307 - val_sparse_categorical_accuracy: 0.9917\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 39s 76ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0063 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0275 - val_sparse_categorical_accuracy: 0.9922\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 42s 82ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0046 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0326 - val_sparse_categorical_accuracy: 0.9919\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 37s 72ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0071 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0342 - val_sparse_categorical_accuracy: 0.9913\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 37s 72ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0051 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0388 - val_sparse_categorical_accuracy: 0.9918\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 37s 73ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0056 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0331 - val_sparse_categorical_accuracy: 0.9921\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 38s 75ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0042 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0419 - val_sparse_categorical_accuracy: 0.9910\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 37s 73ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0063 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0341 - val_sparse_categorical_accuracy: 0.9923\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 38s 75ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0032 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.0294 - val_sparse_categorical_accuracy: 0.9934\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 38s 75ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0054 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0443 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 39s 76ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0037 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0336 - val_sparse_categorical_accuracy: 0.9930\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 38s 75ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0017 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.0325 - val_sparse_categorical_accuracy: 0.9937\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 38s 75ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0018 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.0349 - val_sparse_categorical_accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff9abf68f28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Model with Adam \n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, 5, input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.ReLU(negative_slope=0.01),\n",
    "  tf.keras.layers.Conv2D(64, 5),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.ReLU(negative_slope=0.01),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Flatten(input_shape=(64, 2, 2)),\n",
    "  tf.keras.layers.Dense(128,activation=partial(tf.nn.leaky_relu, alpha=0.01)),\n",
    "  tf.keras.layers.Dense(10, activation=partial(tf.nn.leaky_relu, alpha=0.01))\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=25,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-genesis",
   "metadata": {},
   "source": [
    "Wonderful, Adam showed his great qualities. Let's try the other two baseline optimizers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "yellow-sport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 469 steps, validate on 79 steps\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 37s 71ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.3041 - sparse_categorical_accuracy: 0.9035 - val_loss: 0.0509 - val_sparse_categorical_accuracy: 0.9854\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 37s 72ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0614 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.0360 - val_sparse_categorical_accuracy: 0.9888\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 38s 75ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0406 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.0311 - val_sparse_categorical_accuracy: 0.9902\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 36s 71ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0291 - sparse_categorical_accuracy: 0.9908 - val_loss: 0.0273 - val_sparse_categorical_accuracy: 0.9914\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 36s 71ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0235 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.0264 - val_sparse_categorical_accuracy: 0.9918\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 37s 72ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0194 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.0578 - val_sparse_categorical_accuracy: 0.9825\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 37s 73ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0158 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.0297 - val_sparse_categorical_accuracy: 0.9912\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 37s 73ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0126 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0356 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 37s 74ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0110 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0293 - val_sparse_categorical_accuracy: 0.9930\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 38s 74ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0101 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0277 - val_sparse_categorical_accuracy: 0.9925\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 38s 74ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0082 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0322 - val_sparse_categorical_accuracy: 0.9919\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 38s 74ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0073 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0506 - val_sparse_categorical_accuracy: 0.9877\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 38s 74ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0054 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0408 - val_sparse_categorical_accuracy: 0.9906\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 38s 74ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0055 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0430 - val_sparse_categorical_accuracy: 0.9907\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 38s 74ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0045 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0439 - val_sparse_categorical_accuracy: 0.9910\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 37s 74ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0044 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0406 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 38s 75ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0039 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0434 - val_sparse_categorical_accuracy: 0.9911\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 38s 76ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0042 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0403 - val_sparse_categorical_accuracy: 0.9918\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 38s 75ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0033 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.0407 - val_sparse_categorical_accuracy: 0.9920\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 38s 75ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0031 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.0460 - val_sparse_categorical_accuracy: 0.9923\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 38s 76ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0036 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.0431 - val_sparse_categorical_accuracy: 0.9930\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 38s 75ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0029 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.0502 - val_sparse_categorical_accuracy: 0.9920\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 39s 76ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0028 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.0448 - val_sparse_categorical_accuracy: 0.9915\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 38s 76ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0021 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.0566 - val_sparse_categorical_accuracy: 0.9904\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 39s 76ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0029 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.0476 - val_sparse_categorical_accuracy: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff9806dcf60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the Model with RMSProp \n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, 5, input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.ReLU(negative_slope=0.01),\n",
    "  tf.keras.layers.Conv2D(64, 5),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.ReLU(negative_slope=0.01),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Flatten(input_shape=(64, 2, 2)),\n",
    "  tf.keras.layers.Dense(128,activation=partial(tf.nn.leaky_relu, alpha=0.01)),\n",
    "  tf.keras.layers.Dense(10, activation=partial(tf.nn.leaky_relu, alpha=0.01))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=25,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-directive",
   "metadata": {},
   "source": [
    "RMSPror also does a great job. Now, we will check SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "close-canvas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 469 steps, validate on 79 steps\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 34s 66ms/step - batch: 234.0000 - size: 1.0000 - loss: 1.9903 - sparse_categorical_accuracy: 0.4183 - val_loss: 1.4072 - val_sparse_categorical_accuracy: 0.5434\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 35s 68ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.8630 - sparse_categorical_accuracy: 0.7287 - val_loss: 0.2575 - val_sparse_categorical_accuracy: 0.9264\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 34s 65ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.2056 - sparse_categorical_accuracy: 0.9404 - val_loss: 0.1457 - val_sparse_categorical_accuracy: 0.9555\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 31s 61ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.1444 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1108 - val_sparse_categorical_accuracy: 0.9665\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 31s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.1189 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.1029 - val_sparse_categorical_accuracy: 0.9686\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 30s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.1035 - sparse_categorical_accuracy: 0.9689 - val_loss: 0.0888 - val_sparse_categorical_accuracy: 0.9731\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 30s 58ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0942 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0832 - val_sparse_categorical_accuracy: 0.9747\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 30s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0855 - sparse_categorical_accuracy: 0.9739 - val_loss: 0.0800 - val_sparse_categorical_accuracy: 0.9744\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 31s 60ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0797 - sparse_categorical_accuracy: 0.9762 - val_loss: 0.0683 - val_sparse_categorical_accuracy: 0.9794\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 31s 60ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0738 - sparse_categorical_accuracy: 0.9782 - val_loss: 0.0710 - val_sparse_categorical_accuracy: 0.9777\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 30s 58ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0699 - sparse_categorical_accuracy: 0.9786 - val_loss: 0.0664 - val_sparse_categorical_accuracy: 0.9792\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 31s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0665 - sparse_categorical_accuracy: 0.9796 - val_loss: 0.0596 - val_sparse_categorical_accuracy: 0.9809\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 30s 58ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0627 - sparse_categorical_accuracy: 0.9808 - val_loss: 0.0536 - val_sparse_categorical_accuracy: 0.9824\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 31s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0596 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.0535 - val_sparse_categorical_accuracy: 0.9821\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 30s 58ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0571 - sparse_categorical_accuracy: 0.9829 - val_loss: 0.0555 - val_sparse_categorical_accuracy: 0.9819\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 30s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0552 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.0517 - val_sparse_categorical_accuracy: 0.9830\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 31s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0530 - sparse_categorical_accuracy: 0.9838 - val_loss: 0.0486 - val_sparse_categorical_accuracy: 0.9850\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 30s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0510 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.0466 - val_sparse_categorical_accuracy: 0.9851\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 31s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0495 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.0452 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 31s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0469 - sparse_categorical_accuracy: 0.9861 - val_loss: 0.0480 - val_sparse_categorical_accuracy: 0.9846\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 30s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0461 - sparse_categorical_accuracy: 0.9862 - val_loss: 0.0431 - val_sparse_categorical_accuracy: 0.9857\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 30s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0446 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.0463 - val_sparse_categorical_accuracy: 0.9843\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 31s 59ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0434 - sparse_categorical_accuracy: 0.9861 - val_loss: 0.0423 - val_sparse_categorical_accuracy: 0.9858\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 30s 58ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0423 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.0438 - val_sparse_categorical_accuracy: 0.9852\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 30s 58ms/step - batch: 234.0000 - size: 1.0000 - loss: 0.0412 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.0567 - val_sparse_categorical_accuracy: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff95efc84a8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train with Stochastic Gradient Descent\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, 5, input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.ReLU(negative_slope=0.01),\n",
    "  tf.keras.layers.Conv2D(64, 5),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.ReLU(negative_slope=0.01),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Flatten(input_shape=(64, 2, 2)),\n",
    "  tf.keras.layers.Dense(128,activation=partial(tf.nn.leaky_relu, alpha=0.01)),\n",
    "  tf.keras.layers.Dense(10, activation=partial(tf.nn.leaky_relu, alpha=0.01))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=25,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-activation",
   "metadata": {},
   "source": [
    "The gradient descent performed slightly worse - it was slower to learn and ended up with a slightly lower score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, we will focus on the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "explicit-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_tr), (x_test, y_t) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (-1,28,28,1))\n",
    "x_test = np.reshape(x_test, (-1,28,28,1))\n",
    "y_train = np.zeros((y_tr.shape[0], 10))\n",
    "y_test = np.zeros((y_t.shape[0], 10))\n",
    "for i in range(y_tr.shape[0]):\n",
    "    y_train[i, y_tr[i]] = 1\n",
    "for i in range(y_t.shape[0]):\n",
    "    y_test[i, y_t[i]] = 1\n",
    "y_train = y_train.astype(np.float)\n",
    "y_test = y_test.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expensive-influence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimension agree\n",
      "################################################################################\n",
      "                      Size of configuration space:  86282                       \n",
      "                          Size of training data: 60000                          \n",
      "                   Approximate data cardinality needed: 8628                    \n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "settings = {}\n",
    "settings['batch_size'] = 32\n",
    "settings['hess_batch_size'] = 8\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, 5, input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.ReLU(negative_slope=0.01),\n",
    "  tf.keras.layers.Conv2D(64, 5),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.ReLU(negative_slope=0.01),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Flatten(input_shape=(64, 2, 2)),\n",
    "  tf.keras.layers.Dense(128,activation=partial(tf.nn.leaky_relu, alpha=0.01)),\n",
    "  tf.keras.layers.Dense(10, activation=partial(tf.nn.leaky_relu, alpha=0.01))\n",
    "])\n",
    "\n",
    "# Instante the data object\n",
    "problem = ClassificationProblem(model,dtype = tf.float32)\n",
    "\n",
    "train_data = {problem.x:x_train, problem.y_true:y_train}\n",
    "validation_data = {problem.x:x_test, problem.y_true:y_test}\n",
    "\n",
    "HLModelSettings = HessianlearnModelSettings()\n",
    "HLModelSettings['hessian_low_rank'] = 40\n",
    "#HLModelSettings['globalization'] = None\n",
    "HLModelSettings['max_sweeps'] = 20\n",
    "#HLModelSettings['alpha'] = 5e-2\n",
    "#HLModelSettings['printing_sweep_frequency'] = 10\n",
    "regularization = L2Regularization(problem)\n",
    "settings = {}\n",
    "settings['batch_size'] = 128\n",
    "settings['hess_batch_size'] = 128\n",
    "data = Data(train_data,settings['batch_size'], validation_data = validation_data, hessian_batch_size=128)\n",
    "HLModel = HessianlearnModel(problem,regularization,data,settings = HLModelSettings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "industrial-label",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Using low rank SFN optimizer with fixed step                  \n",
      "                                Batch size = 128                                \n",
      "                            Hessian batch size = 128                            \n",
      "                             Hessian low rank = 40                              \n",
      "################################################################################\n",
      " sweeps    Loss     acc     ||g||   Lossval   accval   maxacc   alpha     rank   \n",
      "  0.00   2.30e+00 14.062% 4.95e-01 2.31e+00 9.610% 9.610% 5.00e-02     0 \n",
      "  1.04   2.16e+00 16.406% 1.13e+00 2.18e+00 15.660% 15.660% 5.00e-02    40 \n",
      "  2.07   2.33e+00 10.938% 1.03e+00 2.35e+00 9.760% 15.660% 5.00e-02    40 \n",
      "  3.11   2.31e+00 14.062% 1.04e+00 2.27e+00 20.320% 20.320% 5.00e-02    40 \n",
      "  4.15   2.28e+00 7.812% 8.02e-01 2.22e+00 15.810% 20.320% 5.00e-02    40 \n",
      "  5.01   2.17e+00 18.750% 3.12e-01 2.18e+00 17.170% 20.320% 5.00e-02    40 \n",
      "  6.05   2.18e+00 18.750% 4.52e-01 2.14e+00 19.220% 20.320% 5.00e-02    40 \n",
      "  7.08   2.15e+00 17.188% 3.15e-01 2.13e+00 19.360% 20.320% 5.00e-02    40 \n",
      "  8.12   2.08e+00 24.219% 5.52e-01 2.12e+00 21.640% 21.640% 5.00e-02    40 \n",
      "  9.16   2.11e+00 17.969% 3.44e-01 2.12e+00 20.600% 21.640% 5.00e-02    40 \n",
      " 10.02   2.07e+00 24.219% 5.95e-01 2.11e+00 24.040% 24.040% 5.00e-02    40 \n",
      " 11.06   2.05e+00 28.125% 5.33e-01 2.09e+00 21.920% 24.040% 5.00e-02    40 \n",
      " 12.10   2.02e+00 21.875% 5.05e-01 2.02e+00 24.680% 24.680% 5.00e-02    40 \n",
      " 13.13   1.79e+00 40.625% 3.15e+00 1.91e+00 35.040% 35.040% 5.00e-02    40 \n",
      " 14.17   2.11e+00 20.312% 2.65e+00 2.11e+00 19.530% 35.040% 5.00e-02    40 \n",
      " 15.03   2.02e+00 25.000% 1.97e+00 2.11e+00 19.610% 35.040% 5.00e-02    40 \n",
      " 16.07   2.03e+00 24.219% 1.47e+00 2.08e+00 23.180% 35.040% 5.00e-02    40 \n",
      " 17.11   2.04e+00 20.312% 4.67e-01 1.97e+00 24.090% 35.040% 5.00e-02    40 \n",
      " 18.14   1.96e+00 23.438% 1.01e+00 1.97e+00 24.510% 35.040% 5.00e-02    40 \n",
      " 19.01   1.92e+00 28.125% 9.70e-01 1.95e+00 25.890% 35.040% 5.00e-02    40 \n",
      " 19.87   1.84e+00 32.812% 6.16e-01                   35.040% 5.00e-02    40 \n"
     ]
    }
   ],
   "source": [
    "HLModel.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-chest",
   "metadata": {},
   "source": [
    "Our proposed method proved to be significantly worse than all the more simple ones. Let's see what happens on the artificial problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-runner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
